":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Install magic**","metadata":{}},{"cell_type":"code","source":"!curl -ssL https://magic.modular.com/ | bash","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-10T09:22:36.206277Z","iopub.execute_input":"2025-05-10T09:22:36.206555Z","iopub.status.idle":"2025-05-10T09:22:38.663186Z","shell.execute_reply.started":"2025-05-10T09:22:36.206535Z","shell.execute_reply":"2025-05-10T09:22:38.662270Z"}},"outputs":[{"name":"stdout","text":"Installing the latest version of Magic...\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n100 49.9M  100 49.9M    0     0  30.3M      0  0:00:01  0:00:01 --:--:--  165M\nDone. The 'magic' binary is in '/root/.modular/bin'\n\nTwo more steps:\n1. To use 'magic', run this command so it's in your PATH:\nsource /root/.bashrc\n2. To build with MAX and Mojo, go to http://modul.ar/get-started\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"**Update path to include magic**","metadata":{}},{"cell_type":"code","source":"import os\nos.environ['PATH'] += ':/root/.modular/bin'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T09:24:32.254553Z","iopub.execute_input":"2025-05-10T09:24:32.255256Z","iopub.status.idle":"2025-05-10T09:24:32.259149Z","shell.execute_reply.started":"2025-05-10T09:24:32.255225Z","shell.execute_reply":"2025-05-10T09:24:32.258382Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!nvcc --version","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Create a new mojo project called 'mojo_kernels'**","metadata":{}},{"cell_type":"code","source":"!magic init mojo_kernels --format mojoproject","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T09:24:38.114425Z","iopub.execute_input":"2025-05-10T09:24:38.114686Z","iopub.status.idle":"2025-05-10T09:24:38.270915Z","shell.execute_reply.started":"2025-05-10T09:24:38.114664Z","shell.execute_reply":"2025-05-10T09:24:38.270101Z"}},"outputs":[{"name":"stdout","text":"\u001b[32mâœ” \u001b[0mCreated /kaggle/working/mojo_kernels/mojoproject.toml\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"%cd mojo_kernels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T09:24:45.049987Z","iopub.execute_input":"2025-05-10T09:24:45.050725Z","iopub.status.idle":"2025-05-10T09:24:45.056748Z","shell.execute_reply.started":"2025-05-10T09:24:45.050697Z","shell.execute_reply":"2025-05-10T09:24:45.056219Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/mojo_kernels\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"**Write out the mojo kernel**","metadata":{}},{"cell_type":"code","source":"%%writefile buffer_add_kernel.mojo\n\nfrom gpu import thread_idx, block_idx, block_dim\nfrom gpu.host import DeviceContext, DeviceBuffer\nfrom layout import Layout, LayoutTensor\nfrom math import iota\n\nalias dtype = DType.uint32\nalias elem_count = 1 << 16\nalias threads = 1 << 10\nalias blocks = Int((elem_count + threads - 1) / threads);\nalias data_layout = Layout.row_major(elem_count)\nalias DataTensor = LayoutTensor[dtype, data_layout, MutableAnyOrigin]\n\nfn buffer_add_kernel(input1: DataTensor, input2: DataTensor, output: DataTensor, elem_count: Int):\n    #Calculate global thread ID\n    tid = (block_idx.x * block_dim.x) + thread_idx.x;\n\n    #Boundary check\n    if tid < elem_count:\n        output[tid] = input1[tid] + input2[tid];\n\nfn main() raises:\n    \n    ctx = DeviceContext()\n    \n    var input_buffer_1 = ctx.enqueue_create_buffer[dtype](elem_count)\n    var input_buffer_2 = ctx.enqueue_create_buffer[dtype](elem_count)\n    var output_buffer = ctx.enqueue_create_buffer[dtype](elem_count)\n    \n    with input_buffer_1.map_to_host() as input_buff_1:\n        iota(input_buff_1.unsafe_ptr(), elem_count)\n    with input_buffer_2.map_to_host() as input_buff_2:\n        iota(input_buff_2.unsafe_ptr(), elem_count)\n\n    # Zero the values on the device as they'll be used to accumulate results\n    _ = output_buffer.enqueue_fill(0)\n    \n    var input1 = DataTensor(input_buffer_1)\n    var input2 = DataTensor(input_buffer_2)\n    var output = DataTensor(output_buffer)\n\n    \n    ctx.enqueue_function[buffer_add_kernel](input1, input2,output,elem_count,\n        grid_dim=blocks,\n        block_dim=threads,\n    )\n    ctx.synchronize()\n    \n    with output_buffer.map_to_host() as host_buffer:\n        print(host_buffer[65535])\n        \n    \n   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T10:19:01.329264Z","iopub.execute_input":"2025-05-10T10:19:01.329894Z","iopub.status.idle":"2025-05-10T10:19:01.335774Z","shell.execute_reply.started":"2025-05-10T10:19:01.329863Z","shell.execute_reply":"2025-05-10T10:19:01.334920Z"}},"outputs":[{"name":"stdout","text":"Writing buffer_add_kernel.mojo\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"!magic run mojo buffer_add_kernel.mojo","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T10:19:09.436726Z","iopub.execute_input":"2025-05-10T10:19:09.437336Z","iopub.status.idle":"2025-05-10T10:19:15.978187Z","shell.execute_reply.started":"2025-05-10T10:19:09.437286Z","shell.execute_reply":"2025-05-10T10:19:15.977384Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K\u001b[32mâ \u001b[0m activating environment                                                        131070\n","output_type":"stream"}],"execution_count":38}]}
